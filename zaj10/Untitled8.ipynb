{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Część 1: Naive Bayes (Spam i Grypa)\n",
        "Krok 1: Zadanie \"Email Spam\" – Obliczenia ręczne\n",
        "Wklej ten kod do pierwszej komórki. Implementujemy tu wzór Bayesa „od zera”, aby zobaczyć, jak powstaje wynik."
      ],
      "metadata": {
        "id": "bjOzEvTJwNkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_spam = {\n",
        "    'Słowo_1': ['darmowy', 'darmowy', 'spotkanie', 'raport', 'oferta', 'darmowy', 'spotkanie', 'oferta', 'raport', 'darmowy', 'spotkanie', 'oferta'],\n",
        "    'Słowo_2': ['wygrana', 'wygrana', 'jutro', 'kwartalny', 'specjalna', 'rabat', 'dziś', 'limitowana', 'miesięczny', 'rabat', 'pilne', 'wyjątkowa'],\n",
        "    'Wykrzyknik': ['TAK', 'TAK', 'NIE', 'NIE', 'TAK', 'TAK', 'NIE', 'TAK', 'NIE', 'TAK', 'NIE', 'TAK'],\n",
        "    'Spam': ['TAK', 'TAK', 'NIE', 'NIE', 'NIE', 'TAK', 'NIE', 'NIE', 'NIE', 'TAK', 'NIE', 'NIE']\n",
        "}\n",
        "df_spam = pd.DataFrame(data_spam)\n",
        "\n",
        "total = len(df_spam)\n",
        "p_spam_tak = len(df_spam[df_spam['Spam'] == 'TAK']) / total\n",
        "p_spam_nie = len(df_spam[df_spam['Spam'] == 'NIE']) / total\n",
        "\n",
        "nowy_email = {'Słowo_1': 'darmowy', 'Słowo_2': 'wygrana', 'Wykrzyknik': 'TAK'}\n",
        "\n",
        "prob_tak = 1.0\n",
        "subset_tak = df_spam[df_spam['Spam'] == 'TAK']\n",
        "for cecha, wartosc in nowy_email.items():\n",
        "    prob_tak *= len(subset_tak[subset_tak[cecha] == wartosc]) / len(subset_tak)\n",
        "\n",
        "prob_nie = 1.0\n",
        "subset_nie = df_spam[df_spam['Spam'] == 'NIE']\n",
        "for cecha, wartosc in nowy_email.items():\n",
        "    prob_nie *= len(subset_nie[subset_nie[cecha] == wartosc]) / len(subset_nie)\n",
        "\n",
        "posterior_tak = p_spam_tak * prob_tak\n",
        "posterior_nie = p_spam_nie * prob_nie\n",
        "\n",
        "norm = posterior_tak + posterior_nie\n",
        "wynik_tak = posterior_tak / norm if norm > 0 else 0\n",
        "wynik_nie = posterior_nie / norm if norm > 0 else 0\n",
        "\n",
        "print(f\"Prawdopodobieństwo SPAM = TAK: {wynik_tak:.4f}\")\n",
        "print(f\"Prawdopodobieństwo SPAM = NIE: {wynik_nie:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5uPxgdbwRen",
        "outputId": "c24a8e9b-bcdb-4f85-ce3d-821291d99559"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prawdopodobieństwo SPAM = TAK: 1.0000\n",
            "Prawdopodobieństwo SPAM = NIE: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Krok 2: Zadanie \"Email Spam\" – Biblioteka Scikit-Learn\n",
        "Teraz użyjemy gotowego modelu, który stosuje \"wygładzanie\" (smoothing), żeby uniknąć problemu mnożenia przez zero."
      ],
      "metadata": {
        "id": "8btSmfb9wuRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "X = enc.fit_transform(df_spam.drop('Spam', axis=1))\n",
        "y = df_spam['Spam'].map({'TAK': 1, 'NIE': 0})\n",
        "\n",
        "model = CategoricalNB(alpha=1.0)\n",
        "model.fit(X, y)\n",
        "\n",
        "test_vector = pd.DataFrame([['darmowy', 'wygrana', 'TAK']], columns=['Słowo_1', 'Słowo_2', 'Wykrzyknik'])\n",
        "test_vector_enc = enc.transform(test_vector)\n",
        "\n",
        "proba = model.predict_proba(test_vector_enc)\n",
        "print(f\"Sklearn P(Spam=TAK): {proba[0][1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzSK2PPTwvKY",
        "outputId": "fec54eba-58e0-474d-d6ec-105d0637e0db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn P(Spam=TAK): 0.9679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Krok 3: Zadanie \"Diagnoza Grypy\"\n",
        "Analizujemy dane medyczne i przewidujemy chorobę dla 3 pacjentów."
      ],
      "metadata": {
        "id": "pRwjxV8Owxkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_grypa = {\n",
        "    'Gorączka': ['wysoka', 'wysoka', 'niska', 'wysoka', 'niska', 'wysoka', 'niska', 'wysoka', 'umiarkowana', 'wysoka', 'niska', 'umiarkowana', 'wysoka', 'niska', 'umiarkowana'],\n",
        "    'Kaszel': ['TAK', 'TAK', 'NIE', 'TAK', 'NIE', 'TAK', 'NIE', 'TAK', 'TAK', 'NIE', 'NIE', 'TAK', 'TAK', 'NIE', 'TAK'],\n",
        "    'Zmęczenie': ['duże', 'duże', 'małe', 'duże', 'małe', 'duże', 'małe', 'umiarkowane', 'duże', 'małe', 'małe', 'umiarkowane', 'duże', 'małe', 'duże'],\n",
        "    'Grypa': ['TAK', 'TAK', 'NIE', 'TAK', 'NIE', 'TAK', 'NIE', 'TAK', 'TAK', 'NIE', 'NIE', 'NIE', 'TAK', 'NIE', 'TAK']\n",
        "}\n",
        "df_grypa = pd.DataFrame(data_grypa)\n",
        "\n",
        "print(df_grypa['Grypa'].value_counts())\n",
        "\n",
        "pacjenci = [\n",
        "    {'Gorączka': 'wysoka', 'Kaszel': 'TAK', 'Zmęczenie': 'duże'},\n",
        "    {'Gorączka': 'niska', 'Kaszel': 'NIE', 'Zmęczenie': 'małe'},\n",
        "    {'Gorączka': 'umiarkowana', 'Kaszel': 'TAK', 'Zmęczenie': 'umiarkowane'}\n",
        "]\n",
        "\n",
        "p_grypa_tak = len(df_grypa[df_grypa['Grypa'] == 'TAK']) / len(df_grypa)\n",
        "p_grypa_nie = len(df_grypa[df_grypa['Grypa'] == 'NIE']) / len(df_grypa)\n",
        "\n",
        "for i, pacjent in enumerate(pacjenci):\n",
        "    prob_tak = 1.0\n",
        "    subset_tak = df_grypa[df_grypa['Grypa'] == 'TAK']\n",
        "    for k, v in pacjent.items():\n",
        "        prob_tak *= len(subset_tak[subset_tak[k] == v]) / len(subset_tak)\n",
        "\n",
        "    prob_nie = 1.0\n",
        "    subset_nie = df_grypa[df_grypa['Grypa'] == 'NIE']\n",
        "    for k, v in pacjent.items():\n",
        "        prob_nie *= len(subset_nie[subset_nie[k] == v]) / len(subset_nie)\n",
        "\n",
        "    post_tak = p_grypa_tak * prob_tak\n",
        "    post_nie = p_grypa_nie * prob_nie\n",
        "    wynik = post_tak / (post_tak + post_nie)\n",
        "\n",
        "    print(f\"Pacjent {chr(65+i)}: P(Grypa=TAK) = {wynik:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52V46t9_wys3",
        "outputId": "b07c2031-544b-403d-d5d9-e446b2ac988d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grypa\n",
            "TAK    8\n",
            "NIE    7\n",
            "Name: count, dtype: int64\n",
            "Pacjent A: P(Grypa=TAK) = 1.0000\n",
            "Pacjent B: P(Grypa=TAK) = 0.0000\n",
            "Pacjent C: P(Grypa=TAK) = 0.9245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Część 2: Zadanie Titanic (Regresja Logistyczna)\n",
        "Krok 4: Wczytanie i przygotowanie danych\n",
        "Wczytujemy zbiór Titanic, usuwamy zbędne kolumny (np. 'deck' ma za dużo braków), uzupełniamy wiek medianą i zamieniamy tekst na liczby (One-Hot Encoding)."
      ],
      "metadata": {
        "id": "cRM4d2FMw1C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "df_clean = df.drop(columns=['deck', 'embark_town', 'alive', 'who', 'adult_male'])\n",
        "df_clean['age'] = df_clean['age'].fillna(df_clean['age'].median())\n",
        "df_clean = df_clean.dropna(subset=['embarked'])\n",
        "\n",
        "df_encoded = pd.get_dummies(df_clean, columns=['sex', 'embarked', 'class'], drop_first=True)\n",
        "\n",
        "X = df_encoded.drop('survived', axis=1)\n",
        "y = df_encoded['survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(f\"Rozmiar zbioru treningowego: {X_train.shape}\")\n",
        "print(f\"Rozmiar zbioru testowego: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Knvqse1w2L-",
        "outputId": "9a0ac538-4100-41f7-ba4d-95d1a04b3c83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rozmiar zbioru treningowego: (711, 11)\n",
            "Rozmiar zbioru testowego: (178, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Krok 5: Budowa modelu i analiza współczynników\n",
        "Trenujemy regresję logistyczną i sprawdzamy, które cechy najbardziej wpływają na przeżycie."
      ],
      "metadata": {
        "id": "5zR9wpLIw4pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "coefs = pd.DataFrame({'cecha': X.columns, 'wspolczynnik': model.coef_[0]})\n",
        "coefs['wplyw_bezwzgledny'] = coefs['wspolczynnik'].abs()\n",
        "coefs = coefs.sort_values('wplyw_bezwzgledny', ascending=False)\n",
        "\n",
        "print(\"Top 3 najważniejsze cechy:\")\n",
        "print(coefs.head(3))\n",
        "\n",
        "coefs['odds_ratio'] = np.exp(coefs['wspolczynnik'])\n",
        "print(\"\\nIloraz szans (Odds Ratio) dla płci męskiej:\")\n",
        "print(coefs[coefs['cecha'] == 'sex_male'][['cecha', 'odds_ratio']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF72cl8tw5XS",
        "outputId": "3da8dc2b-af5e-4a6b-bb2f-bec00c8d6637"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 najważniejsze cechy:\n",
            "      cecha  wspolczynnik  wplyw_bezwzgledny\n",
            "6  sex_male     -2.475732           2.475732\n",
            "0    pclass     -0.783356           0.783356\n",
            "5     alone     -0.624589           0.624589\n",
            "\n",
            "Iloraz szans (Odds Ratio) dla płci męskiej:\n",
            "      cecha  odds_ratio\n",
            "6  sex_male    0.084101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Krok 6: Ewaluacja (Ocena jakości)\n",
        "Sprawdzamy skuteczność modelu na danych testowych."
      ],
      "metadata": {
        "id": "3tV1AEC0xAJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(f\"Accuracy (Dokładność): {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision (Precyzja): {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall (Czułość): {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Specificity (Swoistość): {specificity:.4f}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxBxM2y3w9bQ",
        "outputId": "d4062bfa-931a-4a57-a476-8ea3239dadd3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Dokładność): 0.8258\n",
            "Precision (Precyzja): 0.8246\n",
            "Recall (Czułość): 0.6912\n",
            "Specificity (Swoistość): 0.9091\n",
            "AUC: 0.8650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Krok 7: Eksperymenty z regularyzacją\n",
        "Sprawdzamy, jak parametry modelu wpływają na jego jakość (Zadanie 2.5 i 2.6)."
      ],
      "metadata": {
        "id": "hbFCpOH4xEd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "c_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "print(\"Wpływ parametru C na AUC:\")\n",
        "\n",
        "for c in c_values:\n",
        "    lr = LogisticRegression(C=c, max_iter=1000)\n",
        "    lr.fit(X_train_scaled, y_train)\n",
        "    auc = roc_auc_score(y_test, lr.predict_proba(X_test_scaled)[:, 1])\n",
        "    print(f\"C={c}: AUC={auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auNLBqLPxFS7",
        "outputId": "600f9492-82bd-476b-de72-d10a7d37e3b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wpływ parametru C na AUC:\n",
            "C=0.001: AUC=0.8311\n",
            "C=0.01: AUC=0.8497\n",
            "C=0.1: AUC=0.8606\n",
            "C=1: AUC=0.8646\n",
            "C=10: AUC=0.8647\n",
            "C=100: AUC=0.8648\n"
          ]
        }
      ]
    }
  ]
}